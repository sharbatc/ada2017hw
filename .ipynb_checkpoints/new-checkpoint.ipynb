{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/Users/sharbatc/Academia/Courses/Currently Learning/ada/ADA2017-Tutorials/02 - Intro to Pandas/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are montlhy reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *monthly average* per year of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guinea\n",
    "We begin our analysis importing all the files from a single country (Guinea) and we start to process this data. In fact, each of the three countries has a different format and we want to unify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_guinea = DATA_FOLDER + \"ebola/guinea_data/\"\n",
    "files = glob.glob(path_guinea + '*.csv')\n",
    "df_guinea = [pd.read_csv(f) for f in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to exclude redundant information, we decided to remove the data about the single cities and to keep only the \"Totals\". This choice additionally simplifies our analysis since each file contains a different set of cities. \n",
    "Before excluding this data we sum up each row of the first file (the data corresponding to the different cities), in order to check whether the information in \"Totals\" is correct or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -5.0\n",
       "2       -4.0\n",
       "3       -9.0\n",
       "4      -11.0\n",
       "5     -133.0\n",
       "6     -351.0\n",
       "7     -495.0\n",
       "8       -2.0\n",
       "9       -2.0\n",
       "12      -2.0\n",
       "13    -133.0\n",
       "14    -228.0\n",
       "15    -363.0\n",
       "16     -31.0\n",
       "17     -18.0\n",
       "19     -13.0\n",
       "20    -139.0\n",
       "21     -89.0\n",
       "22    -161.0\n",
       "23    -190.0\n",
       "24     -52.0\n",
       "25     -81.0\n",
       "26      -7.0\n",
       "27      -6.0\n",
       "28    -220.0\n",
       "29    -277.0\n",
       "30     -23.0\n",
       "31     -12.0\n",
       "32      -8.0\n",
       "33      -8.0\n",
       "34      -2.0\n",
       "36   -6376.0\n",
       "37    -864.0\n",
       "38   -5513.0\n",
       "39    -772.0\n",
       "40       NaN\n",
       "41       NaN\n",
       "Name: Diff_tot, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guinea[0]['sum'] = df_guinea[0].iloc[:,3:].sum(axis=1) \n",
    "\n",
    "df_guinea[0]['Diff_tot'] = df_guinea[0]['Totals']-df_guinea[0]['sum']\n",
    "df_guinea[0]['Diff_tot'][df_guinea[0]['Diff_tot'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5d05a391f60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_guinea\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_guinea\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diff_tot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df_guinea[0][df_guinea[0]['Diff_tot'] != 0].ix[40:41,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that in different cases there is no correspondence between our sum and the provided \"Totals\".\n",
    "In particular, in the last two cases we see a significant difference due to the fact that the last two rows only contains NaN values. Given this unavailable information, we decided to relay on the provided \"Totals\" and  exclude the other columns from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea = [df.ix[:,:3] for df in df_guinea]\n",
    "df_guinea[8].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned our Guinea data, we can concatenate the different files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea_all = reduce(lambda x, y: pd.concat([x,y]), df_guinea)\n",
    "df_guinea_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop eventual NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_guinea_all = df_guinea_all.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a label that indicates the country of origin of this data, that will be useful to create a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea_all['Country'] = 'Guinea'\n",
    "df_guinea_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate our research we can filter the data. We are interested in the \"Total new cases registered so far\" (which is the sum of new cases of confirmed, probables and suspects in each day) and \"New deaths registered\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_filtered = df_guinea_all[df_guinea_all['Description'].str.contains(\"New deaths registered\", na=False)]\n",
    "print(df_all_filtered.shape)\n",
    "df_all_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that some descriptions are different in some files. To understand which descriptions are common to all the dataframes, we can count how many times each description is present and sort them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_count = df_all_filtered.groupby(['Description'], as_index = False)['Totals'].count().sort_values(by='Totals', ascending=False)\n",
    "df_all_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that the description \"New deaths registered\" has been used in 21 out of 22 files. The last three have been instead described as \"New deaths registered today\". We can correct this \"mistake\" and finally filter the two groups we are interested in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea_all['Description'].replace(\"New deaths registered today\", \"New deaths registered\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_deaths = df_guinea_all[df_guinea_all['Description'] == \"New deaths registered\"] \n",
    "df_all_cases = df_guinea_all[df_guinea_all['Description'] == \"Total new cases registered so far\"]\n",
    "df_guinea_all = pd.concat([df_all_deaths, df_all_cases], axis=0)\n",
    "df_guinea_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we want to group the samples by country and month of the year. First, we sum up the \"Totals\" that belong to the same month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea_all['Date'] = df_guinea_all['Date'].apply(lambda x: x[:-3])\n",
    "df_guinea_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give to the descriptions new names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_guinea_all['Description'].replace(\"New deaths registered\", \"New deaths\", inplace=True)\n",
    "df_guinea_all['Description'].replace(\"Total new cases registered so far\", \"New cases\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next objective is to transform the \"Totals\" data into numeric values, we sum them by each month and finally compute the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea_all['Totals'] = df_guinea_all['Totals'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guinea_all = df_guinea_all.groupby(['Date','Description', 'Country'], as_index = False)['Totals'].sum()\n",
    "df_guinea_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_guinea_all = df_guinea_all.groupby(['Country','Description'], as_index = False)['Totals'].mean()\n",
    "print(df_guinea_all.shape)\n",
    "df_guinea_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liberia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we repeat the same procedure for the other 2 countries, being careful to treat the data properly, since each dataset has different descriptions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_liberia = DATA_FOLDER + \"ebola/liberia_data/\"\n",
    "files = glob.glob(path_liberia + '*.csv')\n",
    "df_liberia = [pd.read_csv(f) for f in files]\n",
    "df_liberia = [df.ix[:,:3] for df in df_liberia]\n",
    "df_liberia_all = reduce(lambda x, y: pd.concat([x,y]), df_liberia)\n",
    "df_liberia_all = df_liberia_all.rename(columns={'Variable': 'Description', 'National': 'Totals'})\n",
    "df_liberia_all['Country'] = 'Liberia'\n",
    "df_liberia_all = df_liberia_all.dropna()\n",
    "#add a 0 to the month when not present\n",
    "df_liberia_all['Date'] = df_liberia_all['Date'].apply(lambda x: \"0\"+x if x[1]=='/' in str(x) else str(x))\n",
    "#add a 0 to the day when not present\n",
    "df_liberia_all['Date'] = df_liberia_all['Date'].apply(lambda x: x[:2]+\"0\"+x[3:] if x[2]=='/' in str(x) else str(x)) \n",
    " #add \"20\" to the year\n",
    "df_liberia_all['Date'] = df_liberia_all['Date'].apply(lambda x: x[:5]+'20'+x[-2:] if x[-3]=='/' in str(x) else str(x))\n",
    "#remove day info\n",
    "df_liberia_all['Date'] = df_liberia_all['Date'].apply(lambda x: x[:2]+\"/\"+x[-4:]) \n",
    "\n",
    "df_liberia_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liberia_all[df_liberia_all['Description'].str.contains(\"New Case/s\", na=False)  ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_deaths = df_liberia_all[df_liberia_all['Description'] == \"Newly reported deaths\"  ] \n",
    "df_all_cases = df_liberia_all[df_liberia_all['Description'].str.contains(\"New Case/s\", na=False)  ] \n",
    "\n",
    "df_liberia_all = pd.concat([df_all_deaths, df_all_cases], axis=0)\n",
    "\n",
    "df_liberia_all['Description'].replace(\"New Case/s (Suspected)\", \"New cases\", inplace=True)\n",
    "df_liberia_all['Description'].replace(\"New Case/s (Probable)\", \"New cases\", inplace=True)\n",
    "df_liberia_all['Description'].replace(\"New Case/s (confirmed)\", \"New cases\", inplace=True)\n",
    "df_liberia_all['Description'].replace(\"Newly reported deaths\", \"New deaths\", inplace=True)\n",
    "\n",
    "\n",
    "df_liberia_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liberia_all = df_liberia_all.groupby(['Date','Description', 'Country'], as_index = False)['Totals'].sum()\n",
    "df_liberia_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liberia_all = df_liberia_all.groupby(['Country','Description'], as_index = False)['Totals'].mean()\n",
    "print(df_liberia_all.shape)\n",
    "df_liberia_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import datetime\n",
    "#df_liberia_all['Date'] = df_liberia_all['Date'].apply(lambda x: \"0\"+x if x[1]=='/' in str(x) else str(x))\n",
    "#df_liberia_all['Date'] =  df_liberia_all['Date'].apply(lambda x: datetime.strptime( x , '%m/%d/%Y'))\n",
    "#df_liberia_all['Date'] =  df_liberia_all['Date'].apply(lambda x: datetime.strptime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sierra Leone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sl = DATA_FOLDER + \"ebola/sl_data/\"\n",
    "files = glob.glob(path_sl + '*.csv')\n",
    "df_sl = [pd.read_csv(f) for f in files]\n",
    "df_sl_all = reduce(lambda x, y: pd.concat([x,y]), df_sl)\n",
    "df_sl_all = pd.concat([df_sl_all.date, df_sl_all.variable, df_sl_all.National], axis=1)\n",
    "df_sl_all = df_sl_all.rename(columns={'date': 'Date', 'variable': 'Description', 'National': 'Totals'})\n",
    "df_sl_all['Country'] = 'Sierra Leone'\n",
    "df_sl_all = df_sl_all.dropna()\n",
    "\n",
    "df_sl_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cases1 = df_sl_all[df_sl_all['Description'] == \"new_suspected\"  ]\n",
    "df_all_cases2 = df_sl_all[df_sl_all['Description'] == \"new_probable\"  ] \n",
    "df_all_cases3 = df_sl_all[df_sl_all['Description'] == \"new_confirmed\"  ] \n",
    "\n",
    "df_all_cases = pd.concat([df_all_cases1, df_all_cases2, df_all_cases3], axis=0)\n",
    "\n",
    "df_all_deaths = df_sl_all[df_sl_all['Description'].str.contains(\"etc_new_deaths\", na=False)  ] \n",
    "\n",
    "df_sl_all = pd.concat([df_all_deaths, df_all_cases], axis=0)\n",
    "\n",
    "df_sl_all['Description'].replace(\"new_suspected\", \"New cases\", inplace=True)\n",
    "df_sl_all['Description'].replace(\"new_probable\", \"New cases\", inplace=True)\n",
    "df_sl_all['Description'].replace(\"new_confirmed\", \"New cases\", inplace=True)\n",
    "df_sl_all['Description'].replace(\"etc_new_deaths\", \"New deaths\", inplace=True)\n",
    "\n",
    "\n",
    "df_sl_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sl_all = df_sl_all.groupby(['Date','Description', 'Country'], as_index = False)['Totals'].sum()\n",
    "df_sl_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sl_all['Totals'] = df_sl_all['Totals'].apply(pd.to_numeric, errors='coerce')\n",
    "df_sl_all = df_sl_all.groupby(['Country','Description'], as_index = False)['Totals'].mean()\n",
    "print(df_sl_all.shape)\n",
    "df_sl_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_guinea_all, df_sl_all, df_liberia_all ], axis=0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.set_index(['Country', 'Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that in our results the new cases for \"Sierra Leone\" (in particular) and \"Liberia\" seem to be too many. It may be a natural spike in the reported cases of death or an error in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first read the metadata and define barcodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(DATA_FOLDER+'/microbiome/metadata.xls')\n",
    "barcodes = metadata['BARCODE']\n",
    "\n",
    "microbiomeData = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import each spreadsheet from the microbiome folder identified by the barcode to a single DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for barcode in barcodes:\n",
    "    \n",
    "    spreadsheet = pd.read_excel(DATA_FOLDER+'/microbiome/' + str(barcode)+'.xls', header=None, names=['ORGANISM', 'VALUE'])\n",
    "    # Add data from the metadata file as columns\n",
    "    for meta in metadata.columns:\n",
    "        spreadsheet[meta] = metadata[metadata.BARCODE == barcode][meta].item()\n",
    "    \n",
    "    # Replace NaN values by 'unknown'\n",
    "    spreadsheet = spreadsheet.fillna('unknown')\n",
    "    \n",
    "    microbiomeData = pd.concat([microbiomeData,spreadsheet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the index we take the barcode and concatenate it to the last part of the organism identifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the indices are unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series([list(i)[0]+'_'+list(i)[1].split()[-1] for i in microbiomeData[['BARCODE','ORGANISM']].values])\n",
    "microbiomeData.index = indices\n",
    "\n",
    "if not microbiomeData.index.is_unique:\n",
    "    raise Exception('Indices are not unique')\n",
    "    \n",
    "\n",
    "microbiomeData\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/Users/sharbatc/Academia/Courses/Currently Learning/ada/ADA2017-Tutorials/02 - Intro to Pandas/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarking port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')\n",
    "filename = DATA_FOLDER+'/titanic.xls'\n",
    "titanic = pd.read_excel(filename)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of each attribute are given below. It is meaningless to find out the range of attributes which are not numeric (`name`, `home.dest`) and hence we do not give the ranges of these attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeframe = titanic.dtypes.to_frame()\n",
    "typeframe.rename(columns = {0:'data type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_max = titanic.select_dtypes(exclude = ['object']).apply(lambda x: x.max()).to_frame().rename(columns = {0:'max'})\n",
    "titanic_min = titanic.select_dtypes(exclude = ['object']).apply(lambda x: x.min()).to_frame().rename(columns = {0:'min'})\n",
    "titanic_range = titanic.select_dtypes(exclude = ['object']).apply(lambda x: x.max() - x.min()).to_frame().rename(columns = {0:'range'})\n",
    "\n",
    "frames = [titanic_min, titanic_max, titanic_range]\n",
    "pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Categorical` attributes are `pclass`, `sex`, `survived`, `embarked`. We can choose `cabin` and `boat` as categories although there are too many elements in that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['pclass','sex','survived','embarked','cabin']:\n",
    "    titanic[col] = titanic[col].astype('category') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.pclass.cat.categories = ['1st','2nd','3rd']\n",
    "titanic.embarked.cat.categories = ['Cherbourg','Queenstown','Southampton']\n",
    "titanic.survived.cat.categories = ['Perished','Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeframe = titanic.dtypes.to_frame()\n",
    "typeframe.rename(columns = {0:'data type'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Plot histograms for the *travel class*, *embarking port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move forward, we see from the questions that there is no use for a lot of the data stored in our `DataFrame` and so we choose to drop them altogether. We do not use `HierarchicalIndex` to upload the data in the previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['name', 'sibsp','parch','ticket','fare','boat','body','home.dest'], axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (12,5))\n",
    "\n",
    "titanic['pclass'].value_counts(sort=False).plot(kind='bar', ax = axes[0], title = 'Travel Class')\n",
    "axes[0].set_ylabel('Num. of passengers')\n",
    "axes[0].set_xlabel('Class')\n",
    "\n",
    "titanic['embarked'].dropna().value_counts(sort=False).plot(kind='bar', ax = axes[1], title = 'Embarking Point')\n",
    "axes[1].set_ylabel('Num. of passengers')\n",
    "axes[1].set_xlabel('Embarking point')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (12,5))\n",
    "\n",
    "titanic['sex'].value_counts(sort=False).plot(kind='bar', ax = axes[0], title = 'Sex')\n",
    "axes[0].set_ylabel('Num. of passengers')\n",
    "\n",
    "step = 10 #decades\n",
    "bin_range = np.arange(0, titanic['age'].max()+step, step)\n",
    "out, bins  = pd.cut(titanic['age'].dropna(), bins=bin_range, include_lowest=True, right=False, retbins=True)\n",
    "out.value_counts(sort=False).plot(kind = 'bar', ax = axes[1], title = 'Age')\n",
    "axes[1].set_xlabel('Age (discrete decade intervals in years)')\n",
    "axes[1].set_ylabel('Num. of passengers')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "\n",
    "The labels of cabin numbers shown in the `titanic.html` file gives us an idea that there are some passengers (super rich people for sure) who booked more than one room. In all of the cases, they are on the same floor except for a few cases in which we have a spurious floor `F` in front of cabins on other floors. The floor id `F` is not even followed by a number. We thought of removing those and taking the other room which is followed by a number. \n",
    "\n",
    "We also removed the floor `T` which is a single entity, because although there does exist a *tank top*, it is not a deck as shown from the website below. (We are not responsible for the ads which pop up on it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame('https://www.encyclopedia-titanica.org/titanic-deckplans/tank-top.html', width=800, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_cabin = titanic['cabin'].dropna().apply(lambda x: x[2:] if \\\n",
    "                                                (x.startswith(\"F \") or x.startswith(\"T\"))\\\n",
    "                                                else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cabin.groupby([titanic_cabin.str[0]]).size().plot(kind = 'pie',\\\n",
    "                                                       title = 'Proportion of passengers by cabin floor',\\\n",
    "                                                       autopct='%1.1f%%', fontsize=12, figsize = (6,6))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_survived = titanic.groupby(['survived','pclass']).size().unstack(fill_value=0)\n",
    "prop_survived.plot(kind = 'pie',\\\n",
    "                   subplots = True,\\\n",
    "                   title = 'Proportion of survivors for each travel class',\\\n",
    "                   use_index = False,\\\n",
    "                   autopct='%.2f',\\\n",
    "                   colors = ['grey','green'],\\\n",
    "                   figsize=(12,4))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, when it comes to class war, we do see that there is a larger proportion of surviving (61.92%) first class passengers, as compared to third class passengers (25.53%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "\n",
    "None of the columns among `survived`, `pclass` or `sex` have any missing values. That's good news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_prop_sur(df):\n",
    "    perished, survived = df['survived'].value_counts()[0], df['survived'].value_counts()[1]\n",
    "    return survived/(perished+survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize = (6,6))\n",
    "\n",
    "prop_survived_class = titanic.groupby(['pclass','sex']).apply(calc_prop_sur).plot(kind='bar', \\\n",
    "                                                            title = 'Proportion of survivors by class and sex')\n",
    "\n",
    "for p in axes.patches:\n",
    "    axes.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "axes.set_xlabel('Travel class and sex')\n",
    "axes.set_ylabel('Proportion of survivors')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "med = titanic['age'].dropna().median()\n",
    "titanic['age_gt_med'] = ((titanic['age'].dropna())>= med)\n",
    "titanic['age_gt_med'] = titanic['age_gt_med'].astype('category') \n",
    "titanic.age_gt_med.cat.categories = ['Greater than {}'.format(med),'Less than {}'.format(med)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_survived_class = titanic.groupby(['age_gt_med','pclass','sex']).apply(calc_prop_sur).\\\n",
    "                                                to_frame().rename(columns = {0:'proportion'})\n",
    "prop_survived_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_survived_class.index.is_unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
